# Generative AI Terminology

[Generative AI Terminology 🔗] (https://www.coursera.org/learn/introduction-to-computers-and-operating-systems-and-security/lecture/TD3h9/understanding-the-capabilities-of-generative-ai-for-business-functions)

Generative AI Terminology

**နိဒါန်း**

Generative AI သည် အာရုံခံနားလည်မှုနှင့် ပြောင်းလဲမှုများအတွက် လျင်မြန်စွာ ဖွံ့ဖြိုးနေသည့် စက်မှု့ဖန်တီးမှုမှတ်ကဲ့မီဇုကနေ ယေဘူဖြစ်ပါသည်။ အင်တာနယ်မှာဖြစ်ကြတဲ့ အသုံးပြုမှုများအားဖန်တီးနိုင်တဲ့ အထောက်အပံ့ ပေးသည့် အသုံးပြုမှုများ လက်တွဲသည့် ဖွံ့ဖြိုးမှုများ အများအပြားရှူကြပါလို့ သင်တို့၏ ကျိုးကြောင်းဆန်မှုကို တိုးတက်ပေးမှာဖြစ်ပါတယ်။ ဤအာရုံခံနားလည်မှုများ သုံးသပ်ချက်အောက်တွင် ကြိုးပမ်းကြည့်ပါ။

**Artificial intelligence (AI)**

Artificial intelligence (AI) သည် လူသားအတော်စက်ပညာမှုနှင့်ပတ်သက်တဲ့ နယ်ပယ် ဖြစ်ပါတယ်။ အဓိကအားဖြင့် စွမ်းဆောင်နိုင်စွမ်း၊ သင်ယူနိုင်စွမ်း၊ ပြဌာန်းနိုင်စွမ်း၊ လုပ်ငန်းဆောင်တာများတွင် သိမြင်နိုင်စွမ်းတို့ဖြစ်သော အစဉ်အမှတ်ဖြင့် လက်ရှိမှာ တိုးတက်ပြီး ကြီးမြတ်လာနိုင်တဲ့ နယ်ပယ်ဖြစ်ပါတယ်။

Machine Learning

**Machine learning (ML)** သည် အတော်အတန်လိုအပ်သော အာရုံခံနားလည်မှု ပညာများဖြစ်ပြီး အလားအလာများသော စံပြစက်မှုအနုသုန်နည်းပညာများအတွက် သုံးသပ်နိုင်ပြီး ခန့်မှန်းချက်များလုပ်နိုင်တာပါ။

### **အမျိုးအစားများအရ**

- **Supervised learning**: အမှတ်အသားပြထားသော သင်ကြားမှုဒေတာများသုံး၍ သတ်မှတ်ချက်များတွက်ခန့်မှန်းရန် ဆောင်ရွက်ပါသည်။
- **Unsupervised learning**: မတိုင်မီလက်ခံတိုးတက်မှုများဖြစ်ပြီး ချိတ်ဆက်မှုများမှာ ပုံစံများရှာဖွေပါသည်။
- **Reinforcement learning**: ဆုံးဖြတ်မှုများထုတ်လုပ်ရန် တုံ့ပြန်မှုပေးသော ကြံ့ခိုင်သောပြန်အပ်မှုများလေ့လာချက်များပါသည်။

### **Algorithm နှင့် နည်းလမ်းများ**

- **ကုန်ကျစရိတ် မိန့်ဘုတ်များ**: Linear regression, decision trees, neural networks စသည်တို့ ပါဝင်သည်။
- **အဆင့်မြင့်နည်းလမ်းများ**: Deep learning သည် မျိုးစုံသုံးချောင်းနှင့် ကဏ္ဍများအသုံးပြုပြီး ထက်တန်ပါသည်။

### **ဒေတာစီစဉ်ခြင်းနှင့် ထိန်းသိမ်းခြင်း**

- နည်းပြုမှု အားကောင်းသည့် ML သည် တွက်ချက်မှုများမှာ ထိရောက်တဲ့ ဖော်ပြချက်များကို လိုအပ်ပါသည်။
- **ပြင်ဆင်မှုများ**: Normalization, အလားအလာများအား ဖြည့်စွက်ခြင်းများနှင့် feature selection.

### **စွမ်းဆောင်မှုဖြတ်တောက်ခြင်း**

- ML စက်မှုအနုနည်းပညာများကို အသစ်အဆင့်သုံးနိုင်သည့် အချက်အလက်များကို လက်ခံရရှိသော performance metrics တိုင်းတာမှုများ သုံးသည်။

### **အကျိုးပြုရာများ**

- ML ကိုဘဏ္ဍာရေးကဏ္ဍတွင် algorithmic trading, ဆေးဘက်သုံးများတွင် predictive diagnostics, နှင့် လွတ်လပ်နိုင်ခြင်းများအတွက် လမ်းကြောင်းစနစ်များတွင် အသုံးပြုကြသည်။

Deep Learning

**Deep learning (DL)** သည် ML နယ်ပယ်မှ စွမ်းအားမြင့်သော ကဏ္ဍဖြစ်ပြီး အလွှာများပါရှိတဲ့ အတုစက်မှု့နာလှိုင်းများအသုံးပြု၍ များသောလွှာများအရ သတ်မှတ်ထားတဲ့ ထက်ပေါ်နိုင်သည့် neural networks ဖြင့် ဖွံ့ဖြိုးမှုများတည်ဆောက်ပါသည်။ ဤနည်းစနစ်သည် များသော အချက်အလက်များတွင် ကွဲပြားခြားနားမှု များထုတ်ယူ၍ အခြေခံမှ အထိမ်းအမှတ်များကို လေ့လာ၍ အလှည့်အပြောင်းများအတွက် အဆင့်မြင့် ပုံစံများရရှိတတ်ပါသည်။ အလေ့အကျင့်သင်ယူမှုဖြစ်စဉ်များမှာ-

- **Supervised** - အမှတ်အသားပြထားသော သင်ကြားမှုဒေတာများဖြင့် ပြန်လည်ဆောက်တည်နေသည်
- **Semi-supervised** - အမှတ်အသားပြထားသော ဒေတာနှင့် မဲ့သားဒေတာများ ပေါင်းစပ်ကာ အသုံးပြုသည်
- **Unsupervised** - မဲ့သားဒေတာအပေါ်သာ မူတည်သောနည်းစနစ် ဖြစ်သည်

ဤနည်းစနစ်သည် အထူးသဖြင့် ပုံရိပ်အမှတ်လက္ခဏာ, သဘာဝဘာသာစကားလုပ်ဆောင်ချက် (NLP) နှင့် အသံလက္ခဏာသိမြင်မှုတို့တွင် ထူးခြားပြည့်စုံသောအကျိုးသက်ရောက်မှုများရှိပြီး ML နည်းစနစ်များ၏ အထိုက်သင့်အသုံးပြုမှုများတွင် အထောက်အပံ့များပေးနိုင်သည်။ DL သည် GANs အတွက် အခြေခံ AI ဖန်တီးမှုများတွင် ထင်ရှားမှုရရှိစေကာ ၏ နိဒါန်းများအဖြစ် တည်ဆောက်မှုများအတွက် အသုံးပြုသည်။

### **Neural networks**

**Neural networks (NN)** သည် AI နယ်ပယ်တွင် အရင်းအမြစ်အသုံးများဖြစ်၍ သက္ကတပြသလို အာရုံခံနှင့် အချက်အလက်များ သုံးစွဲခြင်းလုပ်ငန်းစဉ်များတွင် ထိရောက်သော နည်းစနစ်ဖြစ်ပါတယ်။ ဤနည်းစနစ်တွင် အလွှာအတော်များသော nodes ကော်စရာများဖြင့် ဖွံ့ဖြိုးပြီး ဒေတာများကို သင့်တော်သော အလှိုင်းဖြစ်စဉ်အတွင်း ပေါ်လာသည်။ ယင်းမှတဆင့် များသောအချက်များအတိုင်း ဆုံးဖြတ်ချက်များခွဲခြားမှတ်သားနိုင်ပြီး အချင်းချင်းရှိသော ဆိုင်ရာဆက်နွယ်မှုများသည် စီစဉ်နိုင်သည်။ ထိုကြောင့်, neural networks များအတွက် တည်ဆောက်မှုများသည် လေ့ကျင့်မှုများနှင့် ထိရောက်မှုများတိုးတက်မှုကို ရွေ့လျားစီစဉ်နိုင်သည်။

NN တွင် training ဖြစ်စဉ်မှာ backpropagation နည်းစနစ်ကို အသုံးပြုပြီး အမှားပေါ်တာကို နှိမ်နိုင်သည့် နည်းလမ်းများဖြင့် ပြန်လည်တည်ဆောက်မှုရှိသည်။

### **စွမ်းဆောင်မှု အချက်အလက်များ**

NN အတွက် စွမ်းဆောင်မှု အချက်အလက်များမှာ computer vision, အသံလက္ခဏာသိမြင်မှု (speech recognition), နှင့် NLP တွင် ပိုထိရောက်သော ဖော်ပြချက်များကို အခြေခံ၍ ဖော်ပြပါသည်။

Generative Adversarial Networks (GAN)

**GANs** သည် ML တွင် အသုံးပြုသည့် လှုပ်ရှားမှုနည်းပညာများဖြစ်ပြီး, ကွဲပြားခြားနားသော နှစ်ခုပွင့်လင်းအောင့်ခြင်းမရှိသော two competing NNs ကို အသုံးပြုသည်: generator နှင့် discriminator. Generator သည် အမှန်တရားဒေတာများကို မထင်မသာတည်ဆောက်ပြီး, Discriminator သည် ထုတ်လုပ်ထားသော ဒေတာသည် အမှန်ဖြစ်၊ မဖြစ် သော်လည်း ကွဲပြားခြားနားနိုင်သည့် အခန်းကဏ္ဍများဖြစ်သည်။ ဤလှုပ်ရှားမှုသည် teacher-student dynamic ကဲ့သို့ဖြစ်ပြီး, ထုတ်လုပ်ထားသော output များ၏ တိကျမှုကို မျှော်လင့်ထားသည်။ Training အနေဖြင့် Discriminator သည် အမှန်နှင့် ထုတ်လုပ်ထားသော ဒေတာများကို ကွဲပြားနိုင်အောင် လေ့ကျင့်၍, Generator သည် လှည့်ဖျားမှု ပိုမိုသက်သာတည်ဆောက်သော နည်းလမ်းများနှင့် တိုးတက်လာသည်။ ဤဖြစ်စဉ်သည် unsupervised learning, semi-supervised learning နှင့် reinforcement learning များတွင် အသုံးပြုသော်လည်း, ကွဲပြားခြားနားသော data samples များတည်ဆောက်ပေးခြင်းအားဖြင့် သာလွန်မှုရှိသည်။ GANs သည် image generation, video creation နှင့် voice synthesis ကဏ္ဍများတွင် ထူးခြားခြားနားသော အထောက်အပံ့ရှိပါသည်။

### Natural Language Processing (NLP)

**NLP** သည် စက်မှုအလိုအလျောက်လုပ်ဆောင်သော AI နယ်ပယ်ကဏ္ဍတွင် အသုံးပြုသည့် နည်းစနစ်ဖြစ်သည်။ အသက်အတွက် စီစဉ်မှုများသည် လူသားအမူအရာများကို ဖတ်ပြီး အဓိပ္ပာယ်ကိန်းများကို လေ့လာနိုင်သည်။ အစောပိုင်းတွင် အသုံးပြုသည့် နည်းစနစ်များသည် Syntax tree parsing, entity recognition နှင့် sentiment analysis တို့ ဖြစ်ပါသည်။ ယင်းနည်းစနစ်များသည် စက်မှုများအား များသော အချက်များကို လေ့လာပြီး, အဓိပ္ပာယ်ကိန်းများကို စီစဉ်နိုင်ရန် အားဖြည့်ပေးပါသည်။ NLP သည် Automated chatbots, translation services, email filtering, နှင့် voice-activated GPS စသည်တို့တွင် အသုံးပြုသော်လည်း, ယင်းတို့အား computer မှာ သိမြင်နိုင်အောင် စီစဉ်လုပ်ဆောင်ပေးသည်။

# Transformers

Transformers သည် deep learning တွင်အရေးကြီးသော တိုးတက်မှုတစ်ခုဖြစ်ပြီး အထူးသဖြင့် NLP ရှုထောင့်မှ အရေးကြီးသည်။ Google သုတေသနပညာရှင်များက ၂၀၁၇ ခုနှစ်တွင် ထုတ်ပြန်သော "Attention is All You Need" စာတမ်းတွင် Transformers ကိုတင်ပြခဲ့ပြီး self-attention ဟုခေါ်သော နည်းစနစ်ကို အသုံးပြုကာ စာကြောင်းတစ်ခုတွင် မည်သည့်စာလုံးမဆို အရေးပါတော့သည်။ ယခင်တုန်းကလို စာလုံးများကို အစဉ်လိုက်ပြုလုပ်ခြင်းမဟုတ်ဘဲ Transformers သည် စကားလုံးအားလုံးကို တပြိုင်နက် ပြုလုပ်သည်။ ဒီအာကာသစက်တင်သည် recurrence နှင့် convolutions ကိုရှောင်ရှား၍ self-attention နှင့် point-wise, fully connected layers များကို Encoder နှင့် Decoder ကိုပါ အသုံးပြုသည်။ ဒီဒီဇိုင်းကြောင့် ပိုမိုမြင့်မားသော သင်ယူမှုများကို လုပ်ဆောင်နိုင်ပြီး machine translation, text summarization, sentiment analysis စသည်ဖြင့် state-of-the-art အောင်မြင်မှုရလဒ်များကို လုပ်ဆောင်နေသည်။

Transformers ၏ sequential data ကို ထိန်းချုပ်နိုင်သော စွမ်းရည်သည် စာသားများအပြင် အခြားနယ်ပယ်များတွင်ပါ အသုံးပြုနိုင်၍ image processing နှင့် even music generation ကဲ့သို့ နယ်ပယ်များတွင်ပါ ထိရောက်သော နည်းပညာပစ္စည်းအဖြစ် အသုံးပြုနိုင်သည်။

# Generative pre-trained transformers

Generative pre-trained transformers (GPT) သည် OpenAI မှထုတ်လုပ်သော state-of-the-art language models ဖြစ်သည်။ DL နည်းပညာများကို အသုံးပြုကာ အထူးသဖြင့် transformer architecture ကို အသုံးပြု၍ နက်ရှိုင်းသော နောက်ခံအချက်အလက်များကို နားလည်ခြင်းနှင့် ဖန်တီးခြင်းအတွက် အသုံးပြုသည်။ ဒီမော်ဒယ်များကို အရင်ဆုံး အကြီးစားအင်တာနက်စာအုပ်များအပေါ် အထူးပြုပြီး ဘာသာစကားဖွဲ့စည်းမှုနှင့် context အားနားလည်ရန် အထူးပြု၍ သင်ကြားသည်။ ဒီ pre-training အဆင့်တွင် unsupervised learning ကို အသုံးပြုပြီး မော်ဒယ်သည် လူအမည်တပ်ထားသော အမှားအယွင်းများမပါဘဲ စာကြောင်းတစ်ခုတွင် နောက်စာလုံးကိုခန့်မှန်းသည်။

ဒီအရာသည် GPT မော်ဒယ်များကို ပေးပို့ထားသော prompts များအပေါ်အခြေခံ၍ သက်ဆိုင်ရာ နှင့် အညီဖြစ်သည့် စာကြောင်းများကိုဖန်တီးနိုင်စေရန် ခွင့်ပြုသည်။ pre-training ပြီးလျှင် GPT မော်ဒယ်များကို specific tasks များတွင် translation, question-answering, summarization စသည်ဖြင့် အသုံးပြုနိုင်အောင် fine-tune လုပ်နိုင်သည်။ လူသားကဲ့သို့သောစာသားများကို ဖန်တီးနိုင်စွမ်းနှင့် ဘာသာစကားအခြေခံသော အလုပ်များကို လုပ်ဆောင်နိုင်စွမ်းသည် AI-assisted writing, conversational agents နှင့် automated content creation စသည့် နယ်ပယ်များတွင် အကျိုးသက်ရောက်မှုရှိစေသည်။

GPT ၏ တစ်ခုခြင်းစီဖြစ်သော ဗားရှင်းများသည် ပိုမိုကြီးမားအောင်ဖြစ်ပြီး အဆင့်မြင့်သို့ဖြစ်လာသည်။ နောက်ဆုံးထွက်သော GPT-4 သည် ၁၇၅ ဘီလီယံ parameters ကိုရှိသဖြင့် ၎င်း၏ သင်ယူမှုနှင့် ဖန်တီးနိုင်စွမ်းအားကောင်းစေသည်။

# Tokenization, Word2vec, and BERT

Tokenization သည် NLP တွင် စာသားများကို စကားလုံးများ၊ စာလုံးများ သို့မဟုတ် subwords ဟုခေါ်သော အင်္ဂါရပ်သေးများအဖြစ် ခွဲခြမ်းခြေခြင်းဖြစ်သည်။ ဒီအဆင့်သည် အမျိုးမျိုးသော NLP မော်ဒယ်များဖြင့် စီမံလုပ်ဆောင်ရန် တကယ်လို့အရေးကြီးသည်။ Word2vec ကို Google ၏ သုတေသနများအနေဖြင့် ဖွံ့ဖြိုးခဲ့ပြီး အနည်းငယ်သော, two-layer neural networks (NNs) ဖြင့် စကားလုံးများကို ကိန်းဂဏန်း vectors အဖြစ် ပြောင်းလဲထားသည်။ ဒီမော်ဒယ်များကို စကားလုံးများ၏ လေ့လာရေး context များကို ပြန်လည်ဖန်တီးရန် ပြန်လည်လေ့လာကြသည်။

တနည်းအားဖြင့်, BERT (Bidirectional Encoder Representations from Transformers) သည် language representations များကို pre-training တွင် ထူးခြားသောတိုးတက်မှုတစ်ခုအဖြစ် ရောက်ရှိလာသည်။ Google မှဖွံ့ဖြိုးခဲ့ပြီး, BERT သည် transformer architecture ကို ပံ့ပိုးကာ စကားလုံးများကို အစဉ်အလာကျကျ မဟုတ်ဘဲ ဝင်နေသော စကားလုံးများအားလုံး၏ အပြန်အလှန်ရည်ရွယ်ချက်အားလုံးကို လုပ်ဆောင်သည်။ ဒီနည်းလမ်းကြောင့် BERT သည် စကားလုံးတစ်လုံးစီ၏ အပြည့်အဝရည်ရွယ်ချက်ကို ဖမ်းဆီးနိုင်ပြီး၊ ဘာသာစကား၏ အနက်အဓိပ္ပါယ်များကို ပိုမိုနက်ရှိုင်းစွာ နားလည်သဘောပေါက်နိုင်စွမ်းရှိသည်။ BERT ၏ context ကို နှစ်ဖက်လုံးမှ ထိန်းချုပ်နိုင်စွမ်းသည့် စွမ်းရည်သည် context အထူးအရေးကြီးသော အလုပ်များတွင် ထူးခြားစွာ အင်အားပျော်ပျော်ဖြစ်စေသည်။

# နိဂုံးချုပ်

ဒီအကြောင်းအရာအတွက် ဖတ်ရှုခြင်းအားဖြင့်, generative AI ၏ မူလအကြောင်းအရာများကို စမ်းသပ်လေ့လာမိပါသည်။ ML, DL, နှင့် NLP အကြောင်းများကိုလည်း သင်လေ့လာခဲ့ပြီး အမျိုးမျိုးသော အလုပ်များတွင် ၎င်းတို့၏ ပါဝင်မှုနှင့် လုပ်ဆောင်မှုများကို စိစစ်ခဲ့ပါသည်။ ထို့အပြင် GANs, transformers နှင့် GPT ကဲ့သို့သော ဖြစ်ထွန်းလာသောဆန်းသစ်ချက်များကိုလည်း စူးစမ်းခဲ့ပြီး ဖန်တီးမှုအသစ်များ ဖန်ဆင်းရာ၌ ၎င်းတို့၏ အရေးပါမှုကို ထင်ရှားသိရှိခဲ့ပါသည်။

Generative AI ၏ မူလသဘောတရားများကို နားလည်ခြင်းက သုတေသန ပရိတ်သတ်များအကြား ဆွေးနွေးမှုများကို ချဲ့ထွင်စေသည့်အပြင် အမျိုးမျိုးသောစက်မှုလုပ်ငန်းများတွင် ၎င်းနည်းပညာကို ထိရောက်စွာအသုံးချရန် ပညာရှင်များအား လုပ်ဆောင်နိုင်စေပါသည်။ AI ဆက်လက်တိုးတက်မှုတွင်, terminologies နှင့် ဆန်းသစ်ချက်များကို လက်တွဲကျွမ်းကျင်စွာ ထိန်းသိမ်းထားခြင်းက ဤ dynamic နယ်ပယ်ကို အောင်မြင်စွာ ကျော်လွှားရန်အတွက် လိုအပ်သော ကိရိယာများကို ဖြည့်ဆည်းပေးပါသည်။
